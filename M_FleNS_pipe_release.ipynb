{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/M-FleNS_NLG-Pipeline/blob/main/M_FleNS_pipe_release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to download and unzip the working folder (once run, click \"Refresh\" on the top left corner to see the folders)\n",
        "from IPython.display import clear_output \n",
        "! gdown 1mDeCiotvWKs7QSiMi3DF-hJmIJhxvH7-\n",
        "! unzip /content/FORGe_colab.zip\n",
        "clear_output()\n",
        "\n",
        "# If any issue, the zip file can be found in the following shared folder: https://drive.google.com/file/d/1mDeCiotvWKs7QSiMi3DF-hJmIJhxvH7-/view?usp=share_link"
      ],
      "metadata": {
        "id": "6-TAUvlK-ccy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to switch to Java 1.8 (needed for FORGe to run correctly)\n",
        "import os\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "metadata": {
        "id": "tUzq-zGLAWZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No need to edit this block for running the generator\n",
        "\n",
        "# The elements of this list are referenced from several places in the code\n",
        "# When updating list, update process_input function!\n",
        "#                 0             1               2                3             4            5            6        7          8           9         10        11\n",
        "level_names = ['PredArg', 'PredArgNorm', 'PredArgAggMark', 'PredArgAgg', 'PredArgPoS', 'PredArgComm', 'DSynt', 'SSynt', 'SSyntAgg', 'DMorphLin', 'REG', 'SMorphText']\n",
        "\n",
        "# Static - Description of RGB modules (FORGe)\n",
        "# Also add dicos here to save some time when loading resources\n",
        "PredArg0_dict = {'input': ['Init'], 'grammars': []}\n",
        "PredArg1_Normalisation_dict = {'input': [level_names[0]], 'grammars': ['10_Con_Sem.rl']}\n",
        "PredArg2_Aggregation_dict = {'input': [level_names[1], level_names[2]], 'grammars': ['11.1_Con_Agg1.rl', '11.2_Con_Agg2.rl', '11.3_Con_Agg3.rl', '11.4_Con_Agg4.rl']}\n",
        "PredArg3_PoSTagging_dict = {'input': [level_names[1], level_names[3]], 'grammars': ['13_Sem_SemPoS.rl']}\n",
        "PredArg4_CommStructuring_dict = {'input': [level_names[4]], 'grammars': ['15_SemPoS_SemCommMark.rl', '17_SemCommMark_SemComm.rl']}\n",
        "DSynt_Structuring_dict = {'input': [level_names[5]], 'grammars': ['20_SemComm_DSynt.rl']}\n",
        "SSynt_Structuring_dict = {'input': [level_names[6]], 'grammars': ['30_DSynt_SSynt.rl', '35_SSynt_PostProc.rl']}\n",
        "SSynt_Aggregation_dict = {'input': [level_names[7]], 'grammars': ['37.1_SSynt_Agg1.rl', '37.2_SSynt_Agg2.rl']}\n",
        "DMorph_AgreementsLinearisation_dict = {'input': [level_names[7], level_names[8]], 'grammars': ['40_SSynt_DMorph_linearize.rl']}\n",
        "SMorph_Processing_dict = {'input': [level_names[9], level_names[10]], 'grammars': ['50_DMorph_SMorph.rl', '60_Smorph_Sentence.rl']}\n",
        "\n",
        "# Paths to FORGe/MATE folders and property files\n",
        "FORGe_input_folder = '/content/FORGe/buddy_project/struct'\n",
        "path_MATE = '/content/FORGe/buddy-patched.jar'\n",
        "path_props_resources_template = '/content/FORGe/mateColabDrive.properties'\n",
        "path_props_levels = '/content/FORGe/mateLevels.properties'\n",
        "path_props = '/content/FORGe/mate.properties'\n",
        "\n",
        "# Paths to general folders\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "str_PredArg_folder = '/content/FORGe/structures/00-PredArg'\n",
        "str_PredArgNorm_folder = '/content/FORGe/structures/01-PredArgNorm'\n",
        "str_PredArgAggMark_folder = '/content/FORGe/structures/02-PredArgAggMark'\n",
        "str_PredArgAgg_folder = '/content/FORGe/structures/03-PredArgAgg'\n",
        "str_PredArgPoS_folder = '/content/FORGe/structures/04-PredArgPoS'\n",
        "str_PredArgComm_folder = '/content/FORGe/structures/05-PredArgComm'\n",
        "str_DSynt_folder = '/content/FORGe/structures/06-DSynt'\n",
        "str_SSynt_folder = '/content/FORGe/structures/07-SSynt'\n",
        "str_SSyntAgg_folder = '/content/FORGe/structures/08-SSyntAgg'\n",
        "str_DMorphLin_folder = '/content/FORGe/structures/09-DMorphLin'\n",
        "str_REG_folder = '/content/FORGe/structures/10-REG'\n",
        "str_SMorphText_folder = '/content/FORGe/structures/11-SMorphText'\n",
        "\n",
        "class RGBModule:\n",
        "  \"Class to store information related to the RGB modules\"\n",
        "  def __init__(self, module, system, dico_module, in_folder, out_folder):\n",
        "    self.module_type = 'RGB'\n",
        "    self.system = system\n",
        "    self.output = str(module)\n",
        "    self.inputs = dico_module.get('input')\n",
        "    self.grammars = dico_module.get('grammars')\n",
        "    self.input_folder = in_folder\n",
        "    self.output_folder = out_folder\n",
        "\n",
        "def clear_files(folder):\n",
        "  \"Function to clear files from a folder.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    for filename in os.listdir(folder):\n",
        "      file_path = os.path.join(folder, filename)\n",
        "      try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "          os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "          shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "def clear_folder(folder):\n",
        "  \"Function to clear whole folders.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    for subfolder in os.listdir(folder):\n",
        "      folder_path = os.path.join(folder, subfolder)\n",
        "      if os.path.isdir(folder_path):\n",
        "        try:\n",
        "          shutil.rmtree(folder_path)\n",
        "        except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (folder, e))\n",
        "\n",
        "def rename_files(folder, output_type):\n",
        "  \"Function that renames files into more a human-friendly format.\"\n",
        "  str_folder_content = os.listdir(folder)\n",
        "  for filename in str_folder_content:\n",
        "    filepath_to_change = os.path.join(folder, filename)\n",
        "    filename_extension = filename.rsplit('.', 1)[1]\n",
        "    filename_noExt = filename.rsplit('.', 1)[0]\n",
        "    clean_filename_noExt = filename_noExt.rsplit('__')[0]\n",
        "    new_filename = clean_filename_noExt+'__'+output_type+'.'+filename_extension\n",
        "    new_filepath = os.path.join(folder, new_filename)\n",
        "    os.rename(filepath_to_change, new_filepath)\n",
        "\n",
        "def copy_files(pathIn, pathOut):\n",
        "  \"Function to copy files into the folder they need to be in to be processed.\"\n",
        "  #print(pathIn)\n",
        "  str_folder_content = os.listdir(pathIn)\n",
        "  for content in str_folder_content:\n",
        "      target_path = os.path.join(pathIn, content)\n",
        "      # If files are found in the folder, copy files to FORGe's input folder \n",
        "      if os.path.isfile(target_path):\n",
        "        shutil.copy(target_path, pathOut)\n",
        "      # If folders are found in the folder, explore them to get to the files\n",
        "      elif os.path.isdir(target_path):\n",
        "        str_subfolder_content = os.listdir(target_path)\n",
        "        for deeper_content in str_subfolder_content:\n",
        "          new_target_path = os.path.join(target_path, deeper_content)\n",
        "          if os.path.isfile(new_target_path):\n",
        "            shutil.copy(new_target_path, pathOut)\n",
        "\n",
        "def check_pipeline(list_modules):\n",
        "  \"Function that finds the first structure to be processed by the pipeline.\"\n",
        "  output_str = []\n",
        "  input_str = []\n",
        "  init_str = []\n",
        "  for module_object in list_modules:\n",
        "    # Output_str is a string\n",
        "    output_str.append(module_object.output)\n",
        "    # Input_str is a list that contains one or more elements\n",
        "    input_str.append(module_object.inputs)\n",
        "  for list_input_level in input_str:\n",
        "    list_seen = []\n",
        "    # For a given module, check for how many input types we find a corresponding structure to process \n",
        "    for unique_input_level in list_input_level:\n",
        "      if unique_input_level in output_str:\n",
        "        list_seen.append(unique_input_level)\n",
        "    # If none of the candidate input types is found, the module is the first to apply in the pipeline\n",
        "    if len(list_seen) == 0:\n",
        "      init_str.append(list_input_level)\n",
        "  # If there is only one list of candidate inputs, that's OK, but if there is none or several, it means the pipeline is wrong.\n",
        "  if len(init_str) == 1:\n",
        "    print('  -> Initial structure is '+str(init_str[0])+'.')\n",
        "    return(init_str[0])\n",
        "  else:\n",
        "    print('! ERROR! Hole in the pipeline, several possible first modules, or mapping not defined in \"process_query\" function for a system ('+str(len(init_str))+' initial representations found: '+str(init_str)+').')\n",
        "    exit()\n",
        "\n",
        "def define_module_sequence(list_modules):\n",
        "  \"Function that creates all possible module sequences and returns the one that include all modules\"\n",
        "  candidate_output_sequence_list = []\n",
        "  # Find first module to apply\n",
        "  for module_object in list_modules:\n",
        "    # At this point we made sure that only one module expects the initial structure type (see check_pipeline function)\n",
        "    if module_object.inputs == list_initial_str:\n",
        "      candidate_output_sequence_list.append([module_object.output])\n",
        "\n",
        "  # Creates all possible sequences of modules and saves them as lists\n",
        "  for candidate_output_sequence in candidate_output_sequence_list:\n",
        "    for module_object in list_modules:\n",
        "      for input_type in module_object.inputs:\n",
        "        if input_type == candidate_output_sequence[-1]:\n",
        "          new_candidate_output_sequence_list = candidate_output_sequence.copy()\n",
        "          new_candidate_output_sequence_list.append(module_object.output)\n",
        "          # Update initial list to keep the loop going\n",
        "          candidate_output_sequence_list.append(new_candidate_output_sequence_list)\n",
        "  # Look for the longest sequence of modules\n",
        "  best_candidate_sequence = []\n",
        "  for candidate_output_sequence in candidate_output_sequence_list:\n",
        "    if len(candidate_output_sequence) > len(best_candidate_sequence):\n",
        "      best_candidate_sequence = candidate_output_sequence\n",
        "  return(best_candidate_sequence)\n",
        "\n",
        "def group_modules(module_sequence, list_modules):\n",
        "  \"Groups consecutive modules that are run by the same system. module_sequence is a list of strings, list_modules a list of objects of class 'module'\"\n",
        "  # Let's make a list that will contain X lists for X different system sub-pipelines; the system name is the first element of each list, the second element is another list that contains the module object.\n",
        "  # grouped_modules looks like this: [['SystemName1', [<Module1-Object>, <Module2-Object>]], ['SystemName2', [<Module3-Object>, <Module4-Object>]]]\n",
        "  grouped_modules = []\n",
        "  # the elements in module_sequence are in order of execution\n",
        "  for output_level in module_sequence:\n",
        "      for module_object in list_modules:\n",
        "          if output_level == module_object.output:\n",
        "            # Check that the first element of the last list is not the same as the currently examined object's system\n",
        "            if len(grouped_modules) > 0:\n",
        "              if len(grouped_modules[-1]) > 0:\n",
        "                if grouped_modules[-1][0] == module_object.system:\n",
        "                  # If the last list has the same system name as the current object, add the object to the group\n",
        "                  grouped_modules[-1][1].append(module_object)\n",
        "                else:\n",
        "                  # Otherwise create the next list for the new system \n",
        "                  grouped_modules.append([module_object.system, [module_object]])\n",
        "              else:\n",
        "                grouped_modules.append([module_object.system, [module_object]])\n",
        "            else:\n",
        "              grouped_modules.append([module_object.system, [module_object]])\n",
        "  return(grouped_modules)\n",
        "\n",
        "def create_grouped_module_objects_FORGe(system_modules):\n",
        "  \"Creates a new object of class RGB module that combines the consecutive modules. system_modules contains at least 2 modules.\"\n",
        "  first_module = system_modules[0]\n",
        "  last_module = system_modules[-1]\n",
        "  grammars_list = []\n",
        "  for module in system_modules:\n",
        "    grammars_list = grammars_list + module.grammars\n",
        "  grouped_dico = {'input': [first_module.inputs], 'grammars': grammars_list}\n",
        "  grouped_module = RGBModule(last_module.output, 'FORGe', grouped_dico, first_module.input_folder, last_module.output_folder)\n",
        "  return(grouped_module)\n",
        "\n",
        "# def check_pipeline(modules, list_init_str):\n",
        "# #  \"Checks if there are holes in the pipeline (i.e. if an expected input structure is not provided by any other module. Is this one usefule now? CF find_initial_structure.\"\n",
        "#   list_outputs = []\n",
        "#   # build list of all outputs pruduced by the different modules\n",
        "#   for module in modules:\n",
        "#     if module.output not in list_outputs:\n",
        "#       list_outputs.append(module.output)\n",
        "#   # check that each module takes as input at least one of the outputs of the other modules\n",
        "#   for module in modules:\n",
        "#     list_input_seen = []\n",
        "#     for input in module.inputs:\n",
        "#       if input in list_outputs or input in list_init_str:\n",
        "#        list_input_seen.append(input)\n",
        "#     if len(list_input_seen) == 0:\n",
        "#      print('ERROR! Incomplete pipeline: there will be no available '+str(input)+' structure (required by '+str(module.output)+' module).')\n",
        "#      exit()\n",
        "\n",
        "def process_query(list_modules, PredArg_Normalisation, PredArg_AggregationMark, PredArg_Aggregation, PredArg_PoSTagging, PredArg_CommStructuring, DSynt_Structuring, SSynt_Structuring, SSynt_Aggregation, DMorph_AgreementsLinearisation, RE_Generation, SMorph_Processing):\n",
        "  \"Function to parse the input parameters and prepare the generation pipeline\"\n",
        "  # For each module, create an object with all the relevant class info (module_name, system, dico_module, in_folder, out_folder)\n",
        "  if PredArg_Normalisation == 'FORGe':\n",
        "    PredArg_Normalisation_RGB = RGBModule(level_names[1], 'FORGe', PredArg1_Normalisation_dict, str_PredArg_folder, str_PredArgNorm_folder)\n",
        "    list_modules.append(PredArg_Normalisation_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if PredArg_AggregationMark == 'FORGe':\n",
        "    pass\n",
        "  else:\n",
        "    pass\n",
        "  if PredArg_Aggregation == 'FORGe':\n",
        "    PredArg_Aggregation_RGB = RGBModule(level_names[3], 'FORGe', PredArg2_Aggregation_dict, str_PredArgNorm_folder, str_PredArgAgg_folder)\n",
        "    list_modules.append(PredArg_Aggregation_RGB)\n",
        "    if PredArg_PoSTagging == 'FORGe':\n",
        "      PredArg_PoSTagging_RGB = RGBModule(level_names[4], 'FORGe', PredArg3_PoSTagging_dict, str_PredArgAgg_folder, str_PredArgPoS_folder)\n",
        "      list_modules.append(PredArg_PoSTagging_RGB)\n",
        "    elif PredArg_PoSTagging == 'HiddenFORGe':\n",
        "      PredArg_PoSTagging_RGB = RGBModule(level_names[4], 'HiddenFORGe', PredArg3_PoSTagging_dict, str_PredArgAgg_folder, str_PredArgPoS_folder)\n",
        "      list_modules.append(PredArg_PoSTagging_RGB)\n",
        "    else:\n",
        "      pass\n",
        "  elif PredArg_PoSTagging == 'FORGe':\n",
        "    PredArg_PoSTagging_RGB = RGBModule(level_names[4], 'FORGe', PredArg3_PoSTagging_dict, str_PredArgNorm_folder, str_PredArgPoS_folder)\n",
        "    list_modules.append(PredArg_PoSTagging_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if PredArg_CommStructuring == 'FORGe':\n",
        "    PredArg_CommStructuring_RGB = RGBModule(level_names[5], 'FORGe', PredArg4_CommStructuring_dict, str_PredArgPoS_folder, str_PredArgComm_folder)\n",
        "    list_modules.append(PredArg_CommStructuring_RGB)\n",
        "  elif PredArg_CommStructuring == 'HiddenFORGe':\n",
        "    PredArg_CommStructuring_RGB = RGBModule(level_names[5], 'HiddenFORGe', PredArg4_CommStructuring_dict, str_PredArgPoS_folder, str_PredArgComm_folder)\n",
        "    list_modules.append(PredArg_CommStructuring_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if DSynt_Structuring == 'FORGe':\n",
        "    DSynt_Structuring_RGB = RGBModule(level_names[6], 'FORGe', DSynt_Structuring_dict, str_PredArgComm_folder, str_DSynt_folder)\n",
        "    list_modules.append(DSynt_Structuring_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if SSynt_Structuring == 'FORGe':\n",
        "    SSynt_Structuring_RGB = RGBModule(level_names[7], 'FORGe', SSynt_Structuring_dict, str_DSynt_folder, str_SSynt_folder)\n",
        "    list_modules.append(SSynt_Structuring_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if SSynt_Aggregation == 'FORGe':\n",
        "    SSynt_Aggregation_RGB = RGBModule(level_names[8], 'FORGe', SSynt_Aggregation_dict, str_SSynt_folder, str_SSyntAgg_folder)\n",
        "    list_modules.append(SSynt_Aggregation_RGB)\n",
        "    if DMorph_AgreementsLinearisation == 'FORGe':\n",
        "      DMorph_AgreementsLinearisation_RGB = RGBModule(level_names[9], 'FORGe', DMorph_AgreementsLinearisation_dict, str_SSyntAgg_folder, str_DMorphLin_folder)\n",
        "      list_modules.append(DMorph_AgreementsLinearisation_RGB)\n",
        "  elif DMorph_AgreementsLinearisation == 'FORGe':\n",
        "    DMorph_AgreementsLinearisation_RGB = RGBModule(level_names[9], 'FORGe', DMorph_AgreementsLinearisation_dict, str_SSynt_folder, str_DMorphLin_folder)\n",
        "    list_modules.append(DMorph_AgreementsLinearisation_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if RE_Generation == 'FORGe':\n",
        "    pass\n",
        "  else:\n",
        "    pass\n",
        "  if SMorph_Processing == 'FORGe':\n",
        "    SMorph_Processing_RGB = RGBModule(level_names[11], 'FORGe', SMorph_Processing_dict, str_DMorphLin_folder, str_SMorphText_folder)\n",
        "    list_modules.append(SMorph_Processing_RGB)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "def process_files_FORGe(module_object):\n",
        "  \"Function to call FORGe to process an input of level X and create an output of level Y\"\n",
        "  \"The function must be called process_files_SystemName\"\n",
        "\n",
        "  # Erase files from input folder\n",
        "  print('Clearing input folder...')\n",
        "  clear_files(FORGe_input_folder)\n",
        "\n",
        "  # Generate mate.properties file, which points to the resources to apply\n",
        "  print('Generating mate.properties file...')\n",
        "  input_folder_gen = module_object.input_folder\n",
        "  output_folder_gen = module_object.output_folder\n",
        "  grammars = module_object.grammars\n",
        "\n",
        "  # Delete existing property file\n",
        "  if os.path.exists(path_props):\n",
        "    os.remove(path_props)\n",
        "\n",
        "  # Read template to create a new file \n",
        "  prop_template = open(path_props_resources_template, 'r')\n",
        "  lines_prop_template = prop_template.readlines()\n",
        "\n",
        "  # Create a new property file\n",
        "  with codecs.open(path_props, 'w', 'utf-8') as f:\n",
        "      for line in lines_prop_template:\n",
        "        if line.startswith('projectDir='):\n",
        "          project_dir = FORGe_input_folder.rsplit('/', 1)[0]\n",
        "          f.write('projectDir='+str(project_dir)+'\\n')\n",
        "        elif line.startswith('ruleSets='):\n",
        "            f.write('ruleSets=')\n",
        "            x = 0\n",
        "            while x < len(grammars) - 1:\n",
        "              f.write(grammars[x])\n",
        "              f.write(', ')\n",
        "              x = x + 1\n",
        "            if x == len(grammars) - 1:\n",
        "              f.write(grammars[x])\n",
        "              f.write('\\n')\n",
        "        elif line.startswith('outputDir='):\n",
        "            f.write('outputDir='+output_folder_gen+'\\n')\n",
        "        elif line.startswith('generateText='):\n",
        "          if output_folder_gen == str_SMorphText_folder:\n",
        "            f.write('generateText=true'+'\\n')\n",
        "          else:\n",
        "            f.write('generateText=false'+'\\n')\n",
        "        else:\n",
        "          f.write(line)\n",
        "  f.close()\n",
        "\n",
        "  # Copy files into input folder\n",
        "  print('Copying files to input folder...')\n",
        "  copy_files(input_folder_gen, FORGe_input_folder)\n",
        "\n",
        "  # Rename files\n",
        "  print('Renaming files in input folder...')\n",
        "  rename_files(FORGe_input_folder, module_object.output)\n",
        "  \n",
        "  # Run generator\n",
        "  print('Running module(s)...')\n",
        "  # Need to hardcode the paths here, otherwise it doesn't work\n",
        "  !java -jar {path_MATE} {path_props} {path_props_levels}\n",
        "\n",
        "def process_files_HiddenFORGe(module_object):\n",
        "  \"Fake function to test the use of several systems in the pipeline\"\n",
        "  \"The function must be called process_files_SystemName\"\n",
        "  process_files_FORGe(module_object)"
      ],
      "metadata": {
        "id": "AlzfD8GT5d65"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa9c_nj1KmZZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "import subprocess\n",
        "import sys\n",
        "from sys import exit\n",
        "import shutil\n",
        "import codecs\n",
        "import re\n",
        "import random\n",
        "\n",
        "!java -version\n",
        "print('=================================================')\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# PARAMETERS FOR GENERATION\n",
        "\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "# E.g. if one a module PredArg_... or DSynt_... is selected, the input predicate-argument structures should be placed in the structures/00-PredArg folder\n",
        "# I'll make the instructions and names clearer in a later (actually usable) version.\n",
        "\n",
        "# Modules to run, with type of processing (FORGe, Model1, SimpleNLG, etc.).\n",
        "# Only FORGe is supported for this prototype version.\n",
        "# What if a module spans over several of these?\n",
        "\n",
        "PredArg_Normalisation = 'FORGe'\n",
        "PredArg_AggregationMark = ''\n",
        "PredArg_Aggregation = 'FORGe'\n",
        "PredArg_PoSTagging = 'FORGe'\n",
        "PredArg_CommStructuring = 'FORGe'\n",
        "DSynt_Structuring = 'FORGe'\n",
        "SSynt_Structuring = 'FORGe'\n",
        "SSynt_Aggregation = 'FORGe'\n",
        "DMorph_AgreementsLinearisation = 'FORGe'\n",
        "# RE_Generation is for now carried out during the previous step; will be separated.\n",
        "RE_Generation = ''\n",
        "SMorph_Processing = 'FORGe'\n",
        "# Define all micro modules and several higher level modules that can overlap, the highest level being the one-shot generation. \n",
        "#Surface_Generation = 'IMS' # That could take DSynt/SSynt as input and return text; to be defined during the query processing\n",
        "\n",
        "# Should consecutive modules for the same system be grouped together or do we want separate calls for each module ('yes'/'no')\n",
        "group_modules_prm = 'no'\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# Erase files from output folders\n",
        "print('Clearing output folders...')\n",
        "clear_folder(str_PredArgNorm_folder)\n",
        "clear_folder(str_PredArgAggMark_folder)\n",
        "clear_folder(str_PredArgAgg_folder)\n",
        "clear_folder(str_PredArgPoS_folder)\n",
        "clear_folder(str_PredArgComm_folder)\n",
        "clear_folder(str_DSynt_folder)\n",
        "clear_folder(str_SSynt_folder)\n",
        "clear_folder(str_SSyntAgg_folder)\n",
        "clear_folder(str_DMorphLin_folder)\n",
        "clear_folder(str_REG_folder)\n",
        "clear_folder(str_SMorphText_folder)\n",
        "\n",
        "# Fill list_modules with module descriptions as objects of a particular Class (e.g. RGB), each of them with associated properties (e.g. input/output types and folders, grammars, etc.)\n",
        "print('Preparing generation pipeline...')\n",
        "list_modules = []\n",
        "process_query(list_modules, PredArg_Normalisation, PredArg_AggregationMark, PredArg_Aggregation, PredArg_PoSTagging, PredArg_CommStructuring, DSynt_Structuring, SSynt_Structuring, SSynt_Aggregation, DMorph_AgreementsLinearisation, RE_Generation, SMorph_Processing)\n",
        "\n",
        "# Just to make sure the code doesn't depend on the nice order of the list (currently the order established in the process_query function)\n",
        "random.shuffle(list_modules)\n",
        "\n",
        "# Find which structure the pipeline starts with, and check for holes in pipeline at the same time\n",
        "list_initial_str = check_pipeline(list_modules)\n",
        "print('  -> '+str(len(list_modules))+' modules were selected.')\n",
        "\n",
        "# Find module sequence that includes all required modules in the right order\n",
        "module_sequence = define_module_sequence(list_modules)\n",
        "print('  -> Sequence: '+str(module_sequence))\n",
        "if len(list_modules) == len(module_sequence):\n",
        "  print('  -> The pipeline looks good, proceeding...')\n",
        "else:\n",
        "  print('! Possible ERROR! There are '+str(len(list_modules))+' modules selected and the longest module sequence found is '+str(len(module_sequence))+'.')\n",
        "\n",
        "# Break pipeline by system, so we can make one call per system instead of one call per module.\n",
        "modules_to_process = group_modules(module_sequence, list_modules)\n",
        "\n",
        "# Run each (sequence of) module(s) with the desired system\n",
        "# One instance of modules to process looks like that: [['SystemName1', [<Module1-Object>, <Module2-Object>]], ['SystemName2', [<Module3-Object>, <Module4-Object>]], ...]\n",
        "# globals()[function_name] allow for caling a function using a string\n",
        "for system_modules in modules_to_process:\n",
        "  function_name = 'process_files_'+system_modules[0]\n",
        "  print('--------------------------')\n",
        "  print('Running '+system_modules[0])\n",
        "  print('--------------------------')\n",
        "  if len(system_modules[1]) > 1:\n",
        "    if group_modules_prm == 'yes':\n",
        "      grouped_module_object = create_grouped_module_objects_FORGe(system_modules[1])\n",
        "      globals()[function_name](grouped_module_object)\n",
        "    else:\n",
        "      for module_object in system_modules[1]:\n",
        "        globals()[function_name](module_object)\n",
        "  else:\n",
        "    globals()[function_name](system_modules[1][0])\n",
        "\n",
        "print('=================================================')\n",
        "print('All done!')"
      ]
    }
  ]
}