{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iaDXEGaXmGtQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/M-FleNS_NLG-Pipeline/blob/main/M_FleNS_pipe_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Did you update FORGe resources?**"
      ],
      "metadata": {
        "id": "j9J8qA2O5PQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to download and unzip the working folder and install Java 8\n",
        "# Once run, click \"Refresh\" on the top left corner to see the folders)\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "# Download FORGe\n",
        "! gdown 1lsh8pwUp9mc0Z_aFbSy1WTIpSx9YwFFD\n",
        "! unzip /content/FORGe_colab_v3_WebNLG.zip\n",
        "log_folder = '/content/FORGe/log'\n",
        "os.makedirs(log_folder)\n",
        "\n",
        "# Clean\n",
        "! rm '/content/FORGe_colab_v3_WebNLG.zip'\n",
        "clear_output()\n",
        "print('Working folder ready!\\n--------------')\n",
        "\n",
        "# Run to switch to Java 1.8 (needed for FORGe to run correctly)\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "metadata": {
        "id": "6-TAUvlK-ccy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323e66b5-7055-4204-b469-2e94e6231afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working folder ready!\n",
            "--------------\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_382\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_382-8u382-ga-1~22.04.1-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to set parameters for generation\n",
        "\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "# E.g. if one a module PredArg_... or DSynt_... is selected, the input predicate-argument structures should be placed in the structures/00-PredArg folder\n",
        "# I'll make the instructions and names clearer in a later (actually usable) version.\n",
        "\n",
        "############# Select language #############\n",
        "language = 'GA' #@param['EN', 'ES', 'FR', 'GA']\n",
        "\n",
        "############# Select dataset split #############\n",
        "split = \"ukn\" #@param['dev', 'test','train','ukn']\n",
        "\n",
        "############# Select module grouping #############\n",
        "# Group consecutive modules for the same system or call each module separately.\n",
        "# Select 'no' to get all intermediate representations, 'yes' if you're only interested in the output.\n",
        "group_modules_prm = 'no' #@param['yes', 'no']\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# Modules to run, with type of processing (FORGe, Model1, SimpleNLG, etc.).\n",
        "# Only FORGe is supported for this prototype version.\n",
        "# What if a module spans over several of these?\n",
        "PredArg_Normalisation = 'FORGe'\n",
        "PredArg_AggregationMark = ''\n",
        "PredArg_Aggregation = 'FORGe'\n",
        "PredArg_PoSTagging = 'FORGe'\n",
        "PredArg_CommStructuring = 'FORGe'\n",
        "DSynt_Structuring = 'FORGe'\n",
        "SSynt_Structuring = 'FORGe'\n",
        "SSynt_Aggregation = 'FORGe'\n",
        "RE_Generation = 'FORGe'\n",
        "DMorph_AgreementsLinearisation = 'FORGe'\n",
        "SMorph_Processing = 'FORGe'\n",
        "# Define all micro modules and several higher level modules that can overlap, the highest level being the one-shot generation.\n",
        "#Surface_Generation = 'IMS' # That could take DSynt/SSynt as input and return text; to be defined during the query processing"
      ],
      "metadata": {
        "id": "QTOh-EV5LB_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static parameters and functions"
      ],
      "metadata": {
        "id": "mLcXOy4qmNHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No need to edit this block for running the generator\n",
        "\n",
        "# The elements of this list are referenced from several places in the code\n",
        "# When updating list, update process_input function!\n",
        "#                 0             1               2                3             4            5            6        7          8        9         10          11\n",
        "level_names = ['PredArg', 'PredArgNorm', 'PredArgAggMark', 'PredArgAgg', 'PredArgPoS', 'PredArgComm', 'DSynt', 'SSynt', 'SSyntAgg', 'REG', 'DMorphLin', 'SMorphText']\n",
        "\n",
        "# Static - Description of RGB modules (FORGe)\n",
        "# Also add dicos here to save some time when loading resources\n",
        "PredArg0_dict = {'input': ['Init'], 'grammars': []}\n",
        "PredArg1_Normalisation_dict = {'input': [level_names[0]], 'grammars': ['10_Con_Sem.rl']}\n",
        "PredArg2_Aggregation_dict = {'input': [level_names[1], level_names[2]], 'grammars': ['11.1_Con_Agg1.rl', '11.2_Con_Agg2.rl', '11.3_Con_Agg3.rl', '11.4_Con_Agg4.rl']}\n",
        "PredArg3_PoSTagging_dict = {'input': [level_names[1], level_names[3]], 'grammars': ['13_Sem_SemPoS.rl']}\n",
        "PredArg4_CommStructuring_dict = {'input': [level_names[4]], 'grammars': ['15_SemPoS_SemCommMark.rl', '17_SemCommMark_SemComm.rl']}\n",
        "DSynt_Structuring_dict = {'input': [level_names[5]], 'grammars': ['20_SemComm_DSynt.rl']}\n",
        "SSynt_Structuring_dict = {'input': [level_names[6]], 'grammars': ['30_DSynt_SSynt.rl', '35_SSynt_PostProc.rl']}\n",
        "SSynt_Aggregation_dict = {'input': [level_names[7]], 'grammars': ['37.1_SSynt_Agg1.rl', '37.2_SSynt_Agg2.rl']}\n",
        "REG_dict = {'input': [level_names[7], level_names[8]], 'grammars': ['38.1_SSynt_REG1.rl', '38.2_SSynt_REG2.rl']}\n",
        "DMorph_AgreementsLinearisation_dict = {'input': [level_names[7], level_names[8], level_names[9]], 'grammars': ['40_SSynt_DMorph_linearize.rl']}\n",
        "SMorph_Processing_dict = {'input': [level_names[10]], 'grammars': ['50_DMorph_SMorph.rl', '60_Smorph_Sentence.rl']}\n",
        "\n",
        "# Static - Description of RGB dicos (FORGe)\n",
        "dic_common_list = ['EN_control.dic', 'concepticon.dic', 'EN_lexicon_MS.dic', 'project_KRISTINA.dic']\n",
        "dic_indep_list = ['language_info.dic', 'lexicon.dic', 'semanticon.dic', 'morphologicon.dic']\n",
        "# If a lexicon.dic, semanticon.dic or morphologicon.dic has something else in the name beyond the language prefix, put in this dictionary\n",
        "dic_special_name_dico = {'EN_lexicon.dic':'EN_lexicon_SMALL.dic'}\n",
        "\n",
        "# Paths to FORGe/MATE folders and property files\n",
        "FORGe_input_folder = '/content/FORGe/buddy_project/struct'\n",
        "path_MATE = '/content/FORGe/buddy-patched.jar'\n",
        "path_props_resources_template = '/content/FORGe/mateColabDrive.properties'\n",
        "path_props_levels = '/content/FORGe/mateLevels.properties'\n",
        "path_props = '/content/FORGe/mate.properties'\n",
        "\n",
        "# Paths to general folders\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "str_PredArg_folder = '/content/FORGe/structures/00-PredArg'\n",
        "str_PredArgNorm_folder = '/content/FORGe/structures/01-PredArgNorm'\n",
        "str_PredArgAggMark_folder = '/content/FORGe/structures/02-PredArgAggMark'\n",
        "str_PredArgAgg_folder = '/content/FORGe/structures/03-PredArgAgg'\n",
        "str_PredArgPoS_folder = '/content/FORGe/structures/04-PredArgPoS'\n",
        "str_PredArgComm_folder = '/content/FORGe/structures/05-PredArgComm'\n",
        "str_DSynt_folder = '/content/FORGe/structures/06-DSynt'\n",
        "str_SSynt_folder = '/content/FORGe/structures/07-SSynt'\n",
        "str_SSyntAgg_folder = '/content/FORGe/structures/08-SSyntAgg'\n",
        "str_REG_folder = '/content/FORGe/structures/09-REG'\n",
        "str_DMorphLin_folder = '/content/FORGe/structures/10-DMorphLin'\n",
        "str_SMorphText_folder = '/content/FORGe/structures/11-SMorphText'\n",
        "\n",
        "class RGBModule:\n",
        "  \"Class to store information related to the RGB modules\"\n",
        "  def __init__(self, module, system, dico_module, in_folder, out_folder):\n",
        "    self.module_type = 'RGB'\n",
        "    self.system = system\n",
        "    self.output = str(module)\n",
        "    self.inputs = dico_module.get('input')\n",
        "    self.grammars = dico_module.get('grammars')\n",
        "    self.input_folder = in_folder\n",
        "    self.output_folder = out_folder\n",
        "\n",
        "def clear_files(folder):\n",
        "  \"Function to clear files from a folder.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    for filename in os.listdir(folder):\n",
        "      file_path = os.path.join(folder, filename)\n",
        "      try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "          os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "          shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "def clear_folder(folder):\n",
        "  \"Function to clear whole folders.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    for subfolder in os.listdir(folder):\n",
        "      folder_path = os.path.join(folder, subfolder)\n",
        "      if os.path.isdir(folder_path):\n",
        "        try:\n",
        "          shutil.rmtree(folder_path)\n",
        "        except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (folder, e))\n",
        "\n",
        "def rename_files(folder, output_type):\n",
        "  \"Function that renames files into more a human-friendly format.\"\n",
        "  str_folder_content = os.listdir(folder)\n",
        "  for filename in str_folder_content:\n",
        "    filepath_to_change = os.path.join(folder, filename)\n",
        "    filename_extension = filename.rsplit('.', 1)[1]\n",
        "    filename_noExt = filename.rsplit('.', 1)[0]\n",
        "    clean_filename_noExt = filename_noExt.rsplit('__')[0]\n",
        "    new_filename = clean_filename_noExt+'__'+output_type+'.'+filename_extension\n",
        "    new_filepath = os.path.join(folder, new_filename)\n",
        "    os.rename(filepath_to_change, new_filepath)\n",
        "\n",
        "def copy_files(pathIn, pathOut):\n",
        "  \"Function to copy files into the folder they need to be in to be processed.\"\n",
        "  #print(pathIn)\n",
        "  str_folder_content = os.listdir(pathIn)\n",
        "  for content in str_folder_content:\n",
        "      target_path = os.path.join(pathIn, content)\n",
        "      # If files are found in the folder, copy files to FORGe's input folder\n",
        "      if os.path.isfile(target_path):\n",
        "        shutil.copy(target_path, pathOut)\n",
        "      # If folders are found in the folder, explore them to get to the files\n",
        "      elif os.path.isdir(target_path):\n",
        "        str_subfolder_content = os.listdir(target_path)\n",
        "        for deeper_content in str_subfolder_content:\n",
        "          new_target_path = os.path.join(target_path, deeper_content)\n",
        "          if os.path.isfile(new_target_path):\n",
        "            shutil.copy(new_target_path, pathOut)\n",
        "\n",
        "def check_pipeline(list_modules):\n",
        "  \"Function that finds the first structure to be processed by the pipeline.\"\n",
        "  output_str = []\n",
        "  input_str = []\n",
        "  init_str = []\n",
        "  for module_object in list_modules:\n",
        "    # Output_str is a string\n",
        "    output_str.append(module_object.output)\n",
        "    # Input_str is a list that contains one or more elements\n",
        "    input_str.append(module_object.inputs)\n",
        "  for list_input_level in input_str:\n",
        "    list_seen = []\n",
        "    # For a given module, check for how many input types we find a corresponding structure to process\n",
        "    for unique_input_level in list_input_level:\n",
        "      if unique_input_level in output_str:\n",
        "        list_seen.append(unique_input_level)\n",
        "    # If none of the candidate input types is found, the module is the first to apply in the pipeline\n",
        "    if len(list_seen) == 0:\n",
        "      init_str.append(list_input_level)\n",
        "  # If there is only one list of candidate inputs, that's OK, but if there is none or several, it means the pipeline is wrong.\n",
        "  if len(init_str) == 1:\n",
        "    print('  -> Initial structure is '+str(init_str[0])+'.')\n",
        "    return(init_str[0])\n",
        "  else:\n",
        "    print('! ERROR! Hole in the pipeline, several possible first modules, or mapping not defined in \"process_query\" function for a system ('+str(len(init_str))+' initial representations found: '+str(init_str)+').')\n",
        "    exit()\n",
        "\n",
        "def define_module_sequence(list_modules):\n",
        "  \"Function that creates all possible module sequences and returns the one that include all modules\"\n",
        "  candidate_output_sequence_list = []\n",
        "  # Find first module to apply\n",
        "  for module_object in list_modules:\n",
        "    # At this point we made sure that only one module expects the initial structure type (see check_pipeline function)\n",
        "    if module_object.inputs == list_initial_str:\n",
        "      candidate_output_sequence_list.append([module_object.output])\n",
        "\n",
        "  # Creates all possible sequences of modules and saves them as lists\n",
        "  for candidate_output_sequence in candidate_output_sequence_list:\n",
        "    for module_object in list_modules:\n",
        "      for input_type in module_object.inputs:\n",
        "        if input_type == candidate_output_sequence[-1]:\n",
        "          new_candidate_output_sequence_list = candidate_output_sequence.copy()\n",
        "          new_candidate_output_sequence_list.append(module_object.output)\n",
        "          # Update initial list to keep the loop going\n",
        "          candidate_output_sequence_list.append(new_candidate_output_sequence_list)\n",
        "  # Look for the longest sequence of modules\n",
        "  best_candidate_sequence = []\n",
        "  for candidate_output_sequence in candidate_output_sequence_list:\n",
        "    if len(candidate_output_sequence) > len(best_candidate_sequence):\n",
        "      best_candidate_sequence = candidate_output_sequence\n",
        "  return(best_candidate_sequence)\n",
        "\n",
        "def group_modules(module_sequence, list_modules):\n",
        "  \"Groups consecutive modules that are run by the same system. module_sequence is a list of strings, list_modules a list of objects of class 'module'\"\n",
        "  # Let's make a list that will contain X lists for X different system sub-pipelines; the system name is the first element of each list, the second element is another list that contains the module object.\n",
        "  # grouped_modules looks like this: [['SystemName1', [<Module1-Object>, <Module2-Object>]], ['SystemName2', [<Module3-Object>, <Module4-Object>]]]\n",
        "  grouped_modules = []\n",
        "  # the elements in module_sequence are in order of execution\n",
        "  for output_level in module_sequence:\n",
        "      for module_object in list_modules:\n",
        "          if output_level == module_object.output:\n",
        "            # Check that the first element of the last list is not the same as the currently examined object's system\n",
        "            if len(grouped_modules) > 0:\n",
        "              if len(grouped_modules[-1]) > 0:\n",
        "                if grouped_modules[-1][0] == module_object.system:\n",
        "                  # If the last list has the same system name as the current object, add the object to the group\n",
        "                  grouped_modules[-1][1].append(module_object)\n",
        "                else:\n",
        "                  # Otherwise create the next list for the new system\n",
        "                  grouped_modules.append([module_object.system, [module_object]])\n",
        "              else:\n",
        "                grouped_modules.append([module_object.system, [module_object]])\n",
        "            else:\n",
        "              grouped_modules.append([module_object.system, [module_object]])\n",
        "  return(grouped_modules)\n",
        "\n",
        "def create_grouped_module_objects_FORGe(system_modules):\n",
        "  \"Creates a new object of class RGB module that combines the consecutive modules. system_modules contains at least 2 modules.\"\n",
        "  first_module = system_modules[0]\n",
        "  last_module = system_modules[-1]\n",
        "  grammars_list = []\n",
        "  for module in system_modules:\n",
        "    grammars_list = grammars_list + module.grammars\n",
        "  grouped_dico = {'input': [first_module.inputs], 'grammars': grammars_list}\n",
        "  grouped_module = RGBModule(last_module.output, 'FORGe', grouped_dico, first_module.input_folder, last_module.output_folder)\n",
        "  return(grouped_module)\n",
        "\n",
        "# def check_pipeline(modules, list_init_str):\n",
        "# #  \"Checks if there are holes in the pipeline (i.e. if an expected input structure is not provided by any other module. Is this one usefule now? CF find_initial_structure.\"\n",
        "#   list_outputs = []\n",
        "#   # build list of all outputs pruduced by the different modules\n",
        "#   for module in modules:\n",
        "#     if module.output not in list_outputs:\n",
        "#       list_outputs.append(module.output)\n",
        "#   # check that each module takes as input at least one of the outputs of the other modules\n",
        "#   for module in modules:\n",
        "#     list_input_seen = []\n",
        "#     for input in module.inputs:\n",
        "#       if input in list_outputs or input in list_init_str:\n",
        "#        list_input_seen.append(input)\n",
        "#     if len(list_input_seen) == 0:\n",
        "#      print('ERROR! Incomplete pipeline: there will be no available '+str(input)+' structure (required by '+str(module.output)+' module).')\n",
        "#      exit()\n",
        "\n",
        "def process_query(list_modules, PredArg_Normalisation, PredArg_AggregationMark, PredArg_Aggregation, PredArg_PoSTagging, PredArg_CommStructuring, DSynt_Structuring, SSynt_Structuring, SSynt_Aggregation, RE_Generation, DMorph_AgreementsLinearisation, SMorph_Processing):\n",
        "  \"Function to parse the input parameters and prepare the generation pipeline\"\n",
        "  # For each module, create an object with all the relevant class info (module_name, system, dico_module, in_folder, out_folder)\n",
        "  if PredArg_Normalisation == 'FORGe':\n",
        "    PredArg_Normalisation_RGB = RGBModule(level_names[1], 'FORGe', PredArg1_Normalisation_dict, str_PredArg_folder, str_PredArgNorm_folder)\n",
        "    list_modules.append(PredArg_Normalisation_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if PredArg_AggregationMark == 'FORGe':\n",
        "    pass\n",
        "  else:\n",
        "    pass\n",
        "  if PredArg_Aggregation == 'FORGe':\n",
        "    PredArg_Aggregation_RGB = RGBModule(level_names[3], 'FORGe', PredArg2_Aggregation_dict, str_PredArgNorm_folder, str_PredArgAgg_folder)\n",
        "    list_modules.append(PredArg_Aggregation_RGB)\n",
        "    if PredArg_PoSTagging == 'FORGe':\n",
        "      PredArg_PoSTagging_RGB = RGBModule(level_names[4], 'FORGe', PredArg3_PoSTagging_dict, str_PredArgAgg_folder, str_PredArgPoS_folder)\n",
        "      list_modules.append(PredArg_PoSTagging_RGB)\n",
        "    elif PredArg_PoSTagging == 'HiddenFORGe':\n",
        "      PredArg_PoSTagging_RGB = RGBModule(level_names[4], 'HiddenFORGe', PredArg3_PoSTagging_dict, str_PredArgAgg_folder, str_PredArgPoS_folder)\n",
        "      list_modules.append(PredArg_PoSTagging_RGB)\n",
        "    else:\n",
        "      pass\n",
        "  elif PredArg_PoSTagging == 'FORGe':\n",
        "    PredArg_PoSTagging_RGB = RGBModule(level_names[4], 'FORGe', PredArg3_PoSTagging_dict, str_PredArgNorm_folder, str_PredArgPoS_folder)\n",
        "    list_modules.append(PredArg_PoSTagging_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if PredArg_CommStructuring == 'FORGe':\n",
        "    PredArg_CommStructuring_RGB = RGBModule(level_names[5], 'FORGe', PredArg4_CommStructuring_dict, str_PredArgPoS_folder, str_PredArgComm_folder)\n",
        "    list_modules.append(PredArg_CommStructuring_RGB)\n",
        "  elif PredArg_CommStructuring == 'HiddenFORGe':\n",
        "    PredArg_CommStructuring_RGB = RGBModule(level_names[5], 'HiddenFORGe', PredArg4_CommStructuring_dict, str_PredArgPoS_folder, str_PredArgComm_folder)\n",
        "    list_modules.append(PredArg_CommStructuring_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if DSynt_Structuring == 'FORGe':\n",
        "    DSynt_Structuring_RGB = RGBModule(level_names[6], 'FORGe', DSynt_Structuring_dict, str_PredArgComm_folder, str_DSynt_folder)\n",
        "    list_modules.append(DSynt_Structuring_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if SSynt_Structuring == 'FORGe':\n",
        "    SSynt_Structuring_RGB = RGBModule(level_names[7], 'FORGe', SSynt_Structuring_dict, str_DSynt_folder, str_SSynt_folder)\n",
        "    list_modules.append(SSynt_Structuring_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  # Agg + REG + Lin\n",
        "  if SSynt_Aggregation == 'FORGe':\n",
        "    SSynt_Aggregation_RGB = RGBModule(level_names[8], 'FORGe', SSynt_Aggregation_dict, str_SSynt_folder, str_SSyntAgg_folder)\n",
        "    list_modules.append(SSynt_Aggregation_RGB)\n",
        "    # Agg + REG + Lin\n",
        "    if RE_Generation == 'FORGe':\n",
        "      REG_RGB = RGBModule(level_names[9], 'FORGe', REG_dict, str_SSyntAgg_folder, str_REG_folder)\n",
        "      list_modules.append(REG_RGB)\n",
        "      # Agg + REG + Lin\n",
        "      if DMorph_AgreementsLinearisation == 'FORGe':\n",
        "        DMorph_AgreementsLinearisation_RGB = RGBModule(level_names[10], 'FORGe', DMorph_AgreementsLinearisation_dict, str_REG_folder, str_DMorphLin_folder)\n",
        "        list_modules.append(DMorph_AgreementsLinearisation_RGB)\n",
        "      else:\n",
        "        pass\n",
        "    # Agg + Lin\n",
        "    elif DMorph_AgreementsLinearisation == 'FORGe':\n",
        "      DMorph_AgreementsLinearisation_RGB = RGBModule(level_names[10], 'FORGe', DMorph_AgreementsLinearisation_dict, str_SSyntAgg_folder, str_DMorphLin_folder)\n",
        "      list_modules.append(DMorph_AgreementsLinearisation_RGB)\n",
        "    else:\n",
        "      pass\n",
        "  # REG + Lin\n",
        "  elif RE_Generation == 'FORGe':\n",
        "    REG_RGB = RGBModule(level_names[9], 'FORGe', REG_dict, str_SSynt_folder, str_REG_folder)\n",
        "    list_modules.append(REG_RGB)\n",
        "    # REG + Lin\n",
        "    if DMorph_AgreementsLinearisation == 'FORGe':\n",
        "      DMorph_AgreementsLinearisation_RGB = RGBModule(level_names[10], 'FORGe', DMorph_AgreementsLinearisation_dict, str_REG_folder, str_DMorphLin_folder)\n",
        "      list_modules.append(DMorph_AgreementsLinearisation_RGB)\n",
        "  # Lin\n",
        "  elif DMorph_AgreementsLinearisation == 'FORGe':\n",
        "    DMorph_AgreementsLinearisation_RGB = RGBModule(level_names[10], 'FORGe', DMorph_AgreementsLinearisation_dict, str_SSynt_folder, str_DMorphLin_folder)\n",
        "    list_modules.append(DMorph_AgreementsLinearisation_RGB)\n",
        "  else:\n",
        "    pass\n",
        "  if SMorph_Processing == 'FORGe':\n",
        "    SMorph_Processing_RGB = RGBModule(level_names[11], 'FORGe', SMorph_Processing_dict, str_DMorphLin_folder, str_SMorphText_folder)\n",
        "    list_modules.append(SMorph_Processing_RGB)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "def process_files_FORGe(module_object):\n",
        "  \"Function to call FORGe to process an input of level X and create an output of level Y\"\n",
        "  \"The function must be called process_files_SystemName\"\n",
        "\n",
        "  # Erase files from input folder\n",
        "  print('  Cleared input folder...')\n",
        "  clear_files(FORGe_input_folder)\n",
        "\n",
        "  # Generate mate.properties file, which points to the resources to apply\n",
        "  print('  Generated mate.properties file...')\n",
        "  input_folder_gen = module_object.input_folder\n",
        "  output_folder_gen = module_object.output_folder\n",
        "  grammars = module_object.grammars\n",
        "  # Create list of dictionaries for generation\n",
        "  dic_resources_list = []\n",
        "  dic_resources_list.extend(dic_common_list)\n",
        "  # Lang. info, Lexicon, semanticon, morphologicon\n",
        "  # We add the language-specific prefix and check if there's a special name for this dico\n",
        "  for dic_name in dic_indep_list:\n",
        "    lspec_dic_name = language+'_'+dic_name\n",
        "    if lspec_dic_name in dic_special_name_dico:\n",
        "      dic_resources_list.append(dic_special_name_dico.get(lspec_dic_name))\n",
        "    else:\n",
        "      dic_resources_list.append(lspec_dic_name)\n",
        "\n",
        "  # Delete existing property file\n",
        "  if os.path.exists(path_props):\n",
        "    os.remove(path_props)\n",
        "\n",
        "  # Read template to create a new file\n",
        "  prop_template = open(path_props_resources_template, 'r')\n",
        "  lines_prop_template = prop_template.readlines()\n",
        "\n",
        "  # Create a new property file\n",
        "  with codecs.open(path_props, 'w', 'utf-8') as f:\n",
        "      for line in lines_prop_template:\n",
        "        if line.startswith('projectDir='):\n",
        "          project_dir = FORGe_input_folder.rsplit('/', 1)[0]\n",
        "          f.write('projectDir='+str(project_dir)+'\\n')\n",
        "        elif line.startswith('resources='):\n",
        "          f.write('resources=')\n",
        "          x = 0\n",
        "          # All but last dico are followed by a comma\n",
        "          while x < len(dic_resources_list) - 1:\n",
        "            f.write(dic_resources_list[x])\n",
        "            f.write(', ')\n",
        "            x = x + 1\n",
        "          # Last dico is followed by a linebreak\n",
        "          if x == len(dic_resources_list) - 1:\n",
        "            f.write(dic_resources_list[x])\n",
        "            f.write('\\n')\n",
        "        elif line.startswith('ruleSets='):\n",
        "            f.write('ruleSets=')\n",
        "            x = 0\n",
        "            while x < len(grammars) - 1:\n",
        "              f.write(grammars[x])\n",
        "              f.write(', ')\n",
        "              x = x + 1\n",
        "            if x == len(grammars) - 1:\n",
        "              f.write(grammars[x])\n",
        "              f.write('\\n')\n",
        "        elif line.startswith('outputDir='):\n",
        "            f.write('outputDir='+output_folder_gen+'\\n')\n",
        "        elif line.startswith('generateText='):\n",
        "          if output_folder_gen == str_SMorphText_folder:\n",
        "            f.write('generateText=true'+'\\n')\n",
        "          else:\n",
        "            f.write('generateText=false'+'\\n')\n",
        "        else:\n",
        "          f.write(line)\n",
        "  f.close()\n",
        "\n",
        "  # Copy files into input folder\n",
        "  print('  Copied files to input folder...')\n",
        "  copy_files(input_folder_gen, FORGe_input_folder)\n",
        "\n",
        "  # Rename files\n",
        "  print('  Renamed files in input folder...')\n",
        "  rename_files(FORGe_input_folder, module_object.output)\n",
        "\n",
        "  # Run generator\n",
        "  print('  Running module(s)...')\n",
        "  !java -jar {path_MATE} {path_props} {path_props_levels} -> \"log.txt\"\n",
        "\n",
        "  # Save log files\n",
        "  new_logname = 'log_'+str(module_object.output)+'.txt'\n",
        "  shutil.move('log.txt', 'FORGe/log/'+new_logname)\n",
        "\n",
        "def process_files_HiddenFORGe(module_object):\n",
        "  \"Fake function to test the use of several systems in the pipeline\"\n",
        "  \"The function must be called process_files_SystemName\"\n",
        "  process_files_FORGe(module_object)"
      ],
      "metadata": {
        "id": "AlzfD8GT5d65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main code"
      ],
      "metadata": {
        "id": "Jbj59kxDmVbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa9c_nj1KmZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95c9e7d-8679-4205-ba32-3ebc7f184f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_382\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_382-8u382-ga-1~22.04.1-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode)\n",
            "=================================================\n",
            "Clearing output folders...\n",
            "Preparing generation pipeline...\n",
            "  -> Initial structure is ['PredArg'].\n",
            "  -> 10 modules were selected.\n",
            "  -> Sequence: ['PredArgNorm', 'PredArgAgg', 'PredArgPoS', 'PredArgComm', 'DSynt', 'SSynt', 'SSyntAgg', 'REG', 'DMorphLin', 'SMorphText']\n",
            "  -> The pipeline looks good, proceeding...\n",
            "--------------------------\n",
            "Running FORGe\n",
            "--------------------------\n",
            "Processing module #0\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #1\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #2\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #3\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #4\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #5\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #6\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #7\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #8\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "Processing module #9\n",
            "  Cleared input folder...\n",
            "  Generated mate.properties file...\n",
            "  Copied files to input folder...\n",
            "  Renamed files in input folder...\n",
            "  Running module(s)...\n",
            "=================================================\n",
            "All done!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import subprocess\n",
        "import sys\n",
        "from sys import exit\n",
        "import shutil\n",
        "import codecs\n",
        "import re\n",
        "import random\n",
        "\n",
        "!java -version\n",
        "print('=================================================')\n",
        "\n",
        "# Erase files from output folders\n",
        "print('Clearing output folders...')\n",
        "clear_folder(str_PredArgNorm_folder)\n",
        "clear_folder(str_PredArgAggMark_folder)\n",
        "clear_folder(str_PredArgAgg_folder)\n",
        "clear_folder(str_PredArgPoS_folder)\n",
        "clear_folder(str_PredArgComm_folder)\n",
        "clear_folder(str_DSynt_folder)\n",
        "clear_folder(str_SSynt_folder)\n",
        "clear_folder(str_SSyntAgg_folder)\n",
        "clear_folder(str_REG_folder)\n",
        "clear_folder(str_DMorphLin_folder)\n",
        "clear_folder(str_SMorphText_folder)\n",
        "clear_folder(log_folder)\n",
        "\n",
        "# Fill list_modules with module descriptions as objects of a particular Class (e.g. RGB), each of them with associated properties (e.g. input/output types and folders, grammars, etc.)\n",
        "print('Preparing generation pipeline...')\n",
        "list_modules = []\n",
        "process_query(list_modules, PredArg_Normalisation, PredArg_AggregationMark, PredArg_Aggregation, PredArg_PoSTagging, PredArg_CommStructuring, DSynt_Structuring, SSynt_Structuring, SSynt_Aggregation, RE_Generation, DMorph_AgreementsLinearisation, SMorph_Processing)\n",
        "\n",
        "# Just to make sure the code doesn't depend on the nice order of the list (currently the order established in the process_query function)\n",
        "random.shuffle(list_modules)\n",
        "\n",
        "# Find which structure the pipeline starts with, and check for holes in pipeline at the same time\n",
        "list_initial_str = check_pipeline(list_modules)\n",
        "print('  -> '+str(len(list_modules))+' modules were selected.')\n",
        "\n",
        "# Find module sequence that includes all required modules in the right order\n",
        "module_sequence = define_module_sequence(list_modules)\n",
        "print('  -> Sequence: '+str(module_sequence))\n",
        "if len(list_modules) == len(module_sequence):\n",
        "  print('  -> The pipeline looks good, proceeding...')\n",
        "else:\n",
        "  print('! Possible ERROR! There are '+str(len(list_modules))+' modules selected and the longest module sequence found is '+str(len(module_sequence))+'.')\n",
        "\n",
        "# Break pipeline by system, so we can make one call per system instead of one call per module.\n",
        "modules_to_process = group_modules(module_sequence, list_modules)\n",
        "\n",
        "# Run each (sequence of) module(s) with the desired system\n",
        "# One instance of modules to process looks like that: [['SystemName1', [<Module1-Object>, <Module2-Object>]], ['SystemName2', [<Module3-Object>, <Module4-Object>]], ...]\n",
        "# globals()[function_name] allow for calling a function using a string\n",
        "for system_modules in modules_to_process:\n",
        "  function_name = 'process_files_'+system_modules[0]\n",
        "  print('--------------------------')\n",
        "  print('Running '+system_modules[0])\n",
        "  print('--------------------------')\n",
        "  if len(system_modules[1]) > 1:\n",
        "    if group_modules_prm == 'yes':\n",
        "      grouped_module_object = create_grouped_module_objects_FORGe(system_modules[1])\n",
        "      globals()[function_name](grouped_module_object)\n",
        "    else:\n",
        "      for module_object in system_modules[1]:\n",
        "        print(\"Processing module #\"+str(system_modules[1].index(module_object)))\n",
        "        globals()[function_name](module_object)\n",
        "  else:\n",
        "    globals()[function_name](system_modules[1][0])\n",
        "\n",
        "print('=================================================')\n",
        "print('All done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check outputs"
      ],
      "metadata": {
        "id": "vhtP4u2W5BKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = '/content/FORGe/structures/00-PredArg'\n",
        "output_folder = '/content/FORGe/structures/11-SMorphText'\n",
        "\n",
        "str_count_perLevel = []\n",
        "txt_count_perLevel = []\n",
        "error_count_perLevel = []\n",
        "\n",
        "def count_conll(filePath):\n",
        "  \"\"\" counts how many conll structures are in a file \"\"\"\n",
        "  counter = 0\n",
        "  fd = codecs.open(filePath, 'r', 'utf-8')\n",
        "  lines = fd.readlines()\n",
        "  for line in lines:\n",
        "    if re.search('^0\\t_', line):\n",
        "      counter += 1\n",
        "  return(counter)\n",
        "\n",
        "def count_txt(filePath):\n",
        "  \"\"\" counts how many texts are in a file \"\"\"\n",
        "  fd = codecs.open(filePath, 'r', 'utf-8')\n",
        "  lines = fd.readlines()\n",
        "  return(len(lines))\n",
        "\n",
        "def examine_files(path, count_perLevel):\n",
        "  folder_content = os.listdir(path)\n",
        "  # Sorting the files so they remain aligned with the outputs\n",
        "  for file in sorted(folder_content):\n",
        "    file_path = os.path.join(path, file)\n",
        "    # If files are found in the folder, process them\n",
        "    # Get number of input structures\n",
        "    if os.path.isfile(file_path):\n",
        "      if re.search('\\.conll', file_path):\n",
        "        count = count_conll(file_path)\n",
        "        count_perLevel.append(count)\n",
        "    # If folders are found in the folder, go deeper\n",
        "    elif os.path.isdir(file_path):\n",
        "      str_subfolder_content = os.listdir(file_path)\n",
        "      # Sorting the folders so they remain aligned with the inputs\n",
        "      for deeper_content in sorted(str_subfolder_content):\n",
        "        new_file_path = os.path.join(file_path, deeper_content)\n",
        "        # Get number of texts\n",
        "        if os.path.isfile(new_file_path):\n",
        "          if re.search('\\.txt', new_file_path):\n",
        "            count = count_txt(new_file_path)\n",
        "            count_perLevel.append(count)\n",
        "\n",
        "def examine_logs(path, count_perLevel):\n",
        "  folder_content = os.listdir(path)\n",
        "  dico_log_errors = {}\n",
        "  for filepath in sorted(folder_content):\n",
        "    if re.search('log_', os.path.basename(filepath)):\n",
        "      level_name = os.path.basename(filepath).split('.')[0].split('log_')[1]\n",
        "      dico_log_errors[level_name] = {}\n",
        "      fd = codecs.open(os.path.join(path, filepath), 'r', 'utf-8')\n",
        "      lines = fd.readlines()\n",
        "      # Look for errors in log files and store how many of them in dico\n",
        "      # E.G. 'DMorphLin': {'train_1triple_ga_utf8_0000-0449': 2, 'train_1triple_ga_utf8_0900-1349': 1, 'train_1triple_ga_utf8_0450-0899': 0}\n",
        "      input_id = 0\n",
        "      for line in lines:\n",
        "        if line.startswith('Processing file '):\n",
        "          input_name = line.split('Processing file ')[1].split('__')[0]\n",
        "          dico_log_errors[level_name][input_name] = []\n",
        "        if re.search('[Ee]rror', line):\n",
        "          dico_log_errors[level_name][input_name].append(input_id)\n",
        "        if  line.startswith('Processing graph output'):\n",
        "          input_id += 1\n",
        "        else:\n",
        "          pass\n",
        "  # print(dico_log_errors)\n",
        "  # Make alist with all errors\n",
        "  # E.g. ['2 errors found in DMorphLin train_1triple_ga_utf8_0000-0449', '1 errors found in DMorphLin train_1triple_ga_utf8_0900-1349']\n",
        "  for level_key, level_values in dico_log_errors.items():\n",
        "    for input_key, input_values in dico_log_errors[level_key].items():\n",
        "      if len(dico_log_errors[level_key][input_key]) > 0:\n",
        "        error = 'Error(s) found in '+str(level_key)+' '+str(input_key)+': '+str(dico_log_errors[level_key][input_key])\n",
        "        count_perLevel.append(error)\n",
        "\n",
        "examine_logs(log_folder, error_count_perLevel)\n",
        "examine_files(input_folder, str_count_perLevel)\n",
        "examine_files(output_folder, txt_count_perLevel)\n",
        "\n",
        "fo = codecs.open('/content/FORGe/log/summary.txt', 'w', 'utf-8')\n",
        "\n",
        "if len(error_count_perLevel) == 0:\n",
        "  print('Log files OK!\\n----')\n",
        "  fo.write('Log files OK!\\n----\\n')\n",
        "else:\n",
        "  print('Error(s) found in log files!\\n----')\n",
        "  fo.write('Error(s) found in log files!\\n----\\n')\n",
        "  print(error_count_perLevel)\n",
        "  fo.write(str(error_count_perLevel)+'\\n')\n",
        "\n",
        "print('\\n')\n",
        "fo.write('\\n')\n",
        "\n",
        "if str_count_perLevel == txt_count_perLevel:\n",
        "  print('Number of texts OK!\\n----')\n",
        "  fo.write('Number of texts OK!\\n----\\n')\n",
        "else:\n",
        "  print('Problem with number of texts!\\n----')\n",
        "  fo.write('Problem with number of texts!\\n----\\n')\n",
        "  print(error_count_perLevel)\n",
        "  fo.write(str(error_count_perLevel)+'\\n')\n",
        "\n",
        "print('Inputs:  ' + str(sum(str_count_perLevel)))\n",
        "fo.write('Inputs:  ' + str(sum(str_count_perLevel))+'\\n')\n",
        "print('Outputs: ' + str(sum(txt_count_perLevel)))\n",
        "fo.write('Outputs: ' + str(sum(txt_count_perLevel))+'\\n')\n",
        "\n",
        "print('Inputs per file:  ' + str(str_count_perLevel))\n",
        "fo.write('Inputs per file:  ' + str(str_count_perLevel)+'\\n')\n",
        "print('Outputs per file: ' + str(txt_count_perLevel))\n",
        "fo.write('Outputs per file: ' + str(txt_count_perLevel)+'\\n')\n",
        "\n",
        "fo.close()\n"
      ],
      "metadata": {
        "id": "SQ1HHQUk5D61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efc3504-1f0b-4f41-a4cc-dfae0fa7e942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log files OK!\n",
            "----\n",
            "\n",
            "\n",
            "Number of texts OK!\n",
            "----\n",
            "Inputs:  31\n",
            "Outputs: 31\n",
            "Inputs per file:  [10, 10, 11]\n",
            "Outputs per file: [10, 10, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zip output folder to download"
      ],
      "metadata": {
        "id": "XDXaA-DDj-A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/WebNLG_[{language}]_[{split}]_allLevels.zip /content/FORGe/structures\n",
        "!zip -r /content/WebNLG_[{language}]_[{split}]_logs.zip /content/FORGe/log"
      ],
      "metadata": {
        "id": "Nw7GmSRzX9Vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf8ec48-7ec7-4f32-ae4d-a734a57b7022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/FORGe/structures/ (stored 0%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/ (stored 0%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/train_1triple_ga_utf8_0450-0899__PredArgNorm.conll/ (stored 0%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/train_1triple_ga_utf8_0450-0899__PredArgNorm.conll/train_1triple_ga_utf8_0450-0899__PredArgNorm.conll_out.str (deflated 85%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/train_1triple_ga_utf8_0900-1349__PredArgNorm.conll/ (stored 0%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/train_1triple_ga_utf8_0900-1349__PredArgNorm.conll/train_1triple_ga_utf8_0900-1349__PredArgNorm.conll_out.str (deflated 83%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/train_1triple_ga_utf8_0000-0449__PredArgNorm.conll/ (stored 0%)\n",
            "  adding: content/FORGe/structures/01-PredArgNorm/train_1triple_ga_utf8_0000-0449__PredArgNorm.conll/train_1triple_ga_utf8_0000-0449__PredArgNorm.conll_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/ (stored 0%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/train_1triple_ga_utf8_0450-0899__SSyntAgg.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/train_1triple_ga_utf8_0450-0899__SSyntAgg.str/train_1triple_ga_utf8_0450-0899__SSyntAgg.str_out.str (deflated 88%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/train_1triple_ga_utf8_0900-1349__SSyntAgg.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/train_1triple_ga_utf8_0900-1349__SSyntAgg.str/train_1triple_ga_utf8_0900-1349__SSyntAgg.str_out.str (deflated 87%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/train_1triple_ga_utf8_0000-0449__SSyntAgg.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/08-SSyntAgg/train_1triple_ga_utf8_0000-0449__SSyntAgg.str/train_1triple_ga_utf8_0000-0449__SSyntAgg.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/02-PredArgAggMark/ (stored 0%)\n",
            "  adding: content/FORGe/structures/06-DSynt/ (stored 0%)\n",
            "  adding: content/FORGe/structures/06-DSynt/train_1triple_ga_utf8_0450-0899__DSynt.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/06-DSynt/train_1triple_ga_utf8_0450-0899__DSynt.str/train_1triple_ga_utf8_0450-0899__DSynt.str_out.str (deflated 87%)\n",
            "  adding: content/FORGe/structures/06-DSynt/train_1triple_ga_utf8_0900-1349__DSynt.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/06-DSynt/train_1triple_ga_utf8_0900-1349__DSynt.str/train_1triple_ga_utf8_0900-1349__DSynt.str_out.str (deflated 85%)\n",
            "  adding: content/FORGe/structures/06-DSynt/train_1triple_ga_utf8_0000-0449__DSynt.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/06-DSynt/train_1triple_ga_utf8_0000-0449__DSynt.str/train_1triple_ga_utf8_0000-0449__DSynt.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/ (stored 0%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/train_1triple_ga_utf8_0450-0899__PredArgComm.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/train_1triple_ga_utf8_0450-0899__PredArgComm.str/train_1triple_ga_utf8_0450-0899__PredArgComm.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/train_1triple_ga_utf8_0900-1349__PredArgComm.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/train_1triple_ga_utf8_0900-1349__PredArgComm.str/train_1triple_ga_utf8_0900-1349__PredArgComm.str_out.str (deflated 84%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/train_1triple_ga_utf8_0000-0449__PredArgComm.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/05-PredArgComm/train_1triple_ga_utf8_0000-0449__PredArgComm.str/train_1triple_ga_utf8_0000-0449__PredArgComm.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/ (stored 0%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/train_1triple_ga_utf8_0450-0899__PredArgAgg.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/train_1triple_ga_utf8_0450-0899__PredArgAgg.str/train_1triple_ga_utf8_0450-0899__PredArgAgg.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/train_1triple_ga_utf8_0900-1349__PredArgAgg.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/train_1triple_ga_utf8_0900-1349__PredArgAgg.str/train_1triple_ga_utf8_0900-1349__PredArgAgg.str_out.str (deflated 84%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/train_1triple_ga_utf8_0000-0449__PredArgAgg.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/03-PredArgAgg/train_1triple_ga_utf8_0000-0449__PredArgAgg.str/train_1triple_ga_utf8_0000-0449__PredArgAgg.str_out.str (deflated 87%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/ (stored 0%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/train_1triple_ga_utf8_0450-0899__DMorphLin.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/train_1triple_ga_utf8_0450-0899__DMorphLin.str/train_1triple_ga_utf8_0450-0899__DMorphLin.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/train_1triple_ga_utf8_0900-1349__DMorphLin.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/train_1triple_ga_utf8_0900-1349__DMorphLin.str/train_1triple_ga_utf8_0900-1349__DMorphLin.str_out.str (deflated 85%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/train_1triple_ga_utf8_0000-0449__DMorphLin.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/10-DMorphLin/train_1triple_ga_utf8_0000-0449__DMorphLin.str/train_1triple_ga_utf8_0000-0449__DMorphLin.str_out.str (deflated 83%)\n",
            "  adding: content/FORGe/structures/09-REG/ (stored 0%)\n",
            "  adding: content/FORGe/structures/09-REG/train_1triple_ga_utf8_0450-0899__REG.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/09-REG/train_1triple_ga_utf8_0450-0899__REG.str/train_1triple_ga_utf8_0450-0899__REG.str_out.str (deflated 89%)\n",
            "  adding: content/FORGe/structures/09-REG/train_1triple_ga_utf8_0000-0449__REG.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/09-REG/train_1triple_ga_utf8_0000-0449__REG.str/train_1triple_ga_utf8_0000-0449__REG.str_out.str (deflated 85%)\n",
            "  adding: content/FORGe/structures/09-REG/train_1triple_ga_utf8_0900-1349__REG.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/09-REG/train_1triple_ga_utf8_0900-1349__REG.str/train_1triple_ga_utf8_0900-1349__REG.str_out.str (deflated 87%)\n",
            "  adding: content/FORGe/structures/00-PredArg/ (stored 0%)\n",
            "  adding: content/FORGe/structures/00-PredArg/train_1triple_ga_utf8_0900-1349.conll (deflated 82%)\n",
            "  adding: content/FORGe/structures/00-PredArg/train_1triple_ga_utf8_0000-0449.conll (deflated 87%)\n",
            "  adding: content/FORGe/structures/00-PredArg/train_1triple_ga_utf8_0450-0899.conll (deflated 83%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/ (stored 0%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0900-1349__SMorphText.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0900-1349__SMorphText.str/train_1triple_ga_utf8_0900-1349__SMorphText.str_out.txt (deflated 69%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0900-1349__SMorphText.str/train_1triple_ga_utf8_0900-1349__SMorphText.str_out.str (deflated 88%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0000-0449__SMorphText.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0000-0449__SMorphText.str/train_1triple_ga_utf8_0000-0449__SMorphText.str_out.txt (deflated 75%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0000-0449__SMorphText.str/train_1triple_ga_utf8_0000-0449__SMorphText.str_out.str (deflated 84%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0450-0899__SMorphText.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0450-0899__SMorphText.str/train_1triple_ga_utf8_0450-0899__SMorphText.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/11-SMorphText/train_1triple_ga_utf8_0450-0899__SMorphText.str/train_1triple_ga_utf8_0450-0899__SMorphText.str_out.txt (deflated 72%)\n",
            "  adding: content/FORGe/structures/07-SSynt/ (stored 0%)\n",
            "  adding: content/FORGe/structures/07-SSynt/train_1triple_ga_utf8_0900-1349__SSynt.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/07-SSynt/train_1triple_ga_utf8_0900-1349__SSynt.str/train_1triple_ga_utf8_0900-1349__SSynt.str_out.str (deflated 85%)\n",
            "  adding: content/FORGe/structures/07-SSynt/train_1triple_ga_utf8_0000-0449__SSynt.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/07-SSynt/train_1triple_ga_utf8_0000-0449__SSynt.str/train_1triple_ga_utf8_0000-0449__SSynt.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/07-SSynt/train_1triple_ga_utf8_0450-0899__SSynt.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/07-SSynt/train_1triple_ga_utf8_0450-0899__SSynt.str/train_1triple_ga_utf8_0450-0899__SSynt.str_out.str (deflated 88%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/ (stored 0%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/train_1triple_ga_utf8_0000-0449__PredArgPoS.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/train_1triple_ga_utf8_0000-0449__PredArgPoS.str/train_1triple_ga_utf8_0000-0449__PredArgPoS.str_out.str (deflated 85%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/train_1triple_ga_utf8_0450-0899__PredArgPoS.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/train_1triple_ga_utf8_0450-0899__PredArgPoS.str/train_1triple_ga_utf8_0450-0899__PredArgPoS.str_out.str (deflated 86%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/train_1triple_ga_utf8_0900-1349__PredArgPoS.str/ (stored 0%)\n",
            "  adding: content/FORGe/structures/04-PredArgPoS/train_1triple_ga_utf8_0900-1349__PredArgPoS.str/train_1triple_ga_utf8_0900-1349__PredArgPoS.str_out.str (deflated 84%)\n",
            "  adding: content/FORGe/log/ (stored 0%)\n",
            "  adding: content/FORGe/log/log_PredArgAgg.txt (deflated 84%)\n",
            "  adding: content/FORGe/log/log_PredArgNorm.txt (deflated 84%)\n",
            "  adding: content/FORGe/log/log_PredArgComm.txt (deflated 84%)\n",
            "  adding: content/FORGe/log/log_PredArgPoS.txt (deflated 84%)\n",
            "  adding: content/FORGe/log/log_REG.txt (deflated 83%)\n",
            "  adding: content/FORGe/log/log_SSynt.txt (deflated 83%)\n",
            "  adding: content/FORGe/log/log_SMorphText.txt (deflated 86%)\n",
            "  adding: content/FORGe/log/summary.txt (deflated 40%)\n",
            "  adding: content/FORGe/log/log_SSyntAgg.txt (deflated 84%)\n",
            "  adding: content/FORGe/log/log_DSynt.txt (deflated 84%)\n",
            "  adding: content/FORGe/log/log_DMorphLin.txt (deflated 84%)\n"
          ]
        }
      ]
    }
  ]
}